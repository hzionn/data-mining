{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FKxmxldFtE47"
   },
   "source": [
    "Data Mining 作業一 Association Rules Frequent Itemset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oDS5M8Vls1Yp"
   },
   "source": [
    "# Description\n",
    "\n",
    "此次作業主要目的在讓同學學習運用 python 由 Foodmart Database 超級市場的顧客及其交易資料中，\n",
    "\n",
    "以 **Apriori**, **FP-Tree** Algorithm 探勘 *Frequent Itemsets*, *Association Rules*, *Multi-level Association Rules*, *Quantitative Association Rules*。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zVb64vKtNR8"
   },
   "source": [
    "- 作業給定的 Foodmart Database 已經附在 WM5 平台上。\n",
    "- 作業每人繳交一份報告，檔案類型以 pdf 為限。上傳檔名格式為 學號_HW1，EX:\n",
    "110753XXX_HW1.pdf\n",
    "- 此次作業交易資料只針對 1998 年的資料 (`sales_fact_1998` + `sales_dec_1998`)\n",
    "- 此次作業可以使用現有套件執行運算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w11g3sm8rHXS"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jrRPnfdYqrWg"
   },
   "outputs": [],
   "source": [
    "# working directory on google drive\n",
    "#wdir = \"drive/MyDrive/NCCU_courses/資料挖掘/hw1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rylHUOVloLyc"
   },
   "outputs": [],
   "source": [
    "# working directory on local\n",
    "wdir = \"./\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1665761961459,
     "user": {
      "displayName": "何子安",
      "userId": "06861626017998849506"
     },
     "user_tz": -480
    },
    "id": "Dc4hsy_grGGy",
    "outputId": "c2483c93-7500-428e-bcfd-30b065262412"
   },
   "outputs": [],
   "source": [
    "# list directory in working directory\n",
    "listdir(wdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jIoFsqvluSpr"
   },
   "outputs": [],
   "source": [
    "# reading .csv\n",
    "sales_fact_1998 = pd.read_csv(wdir + \"hw1_data/sales_fact_1998.csv\")\n",
    "sales_dec_1998 = pd.read_csv(wdir + \"hw1_data/sales_fact_dec_1998.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RnoGkj2mK6k9"
   },
   "source": [
    "# Concat two df\n",
    "\n",
    "concat `sales_fact_1998` & `sales_dec_1998` into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cx1RIImSK-ZV"
   },
   "outputs": [],
   "source": [
    "# concat and reindex\n",
    "df = pd.concat([sales_fact_1998, sales_dec_1998], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVtbXjp2LNA2"
   },
   "outputs": [],
   "source": [
    "# make sure we had the concatenation right\n",
    "assert len(sales_fact_1998) + len(sales_dec_1998) == df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1665764966281,
     "user": {
      "displayName": "何子安",
      "userId": "06861626017998849506"
     },
     "user_tz": -480
    },
    "id": "FfUO407SLNDd",
    "outputId": "ceed3733-ac4a-4b8f-b890-6b472e6f942f"
   },
   "outputs": [],
   "source": [
    "# take a peek at the dataframe\n",
    "print(\"shape:\", df.shape)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ihazzBBBRb5G"
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665764968572,
     "user": {
      "displayName": "何子安",
      "userId": "06861626017998849506"
     },
     "user_tz": -480
    },
    "id": "5IwFMDCiLNJg",
    "outputId": "1a984fec-31eb-49c1-e5f4-3f487e1ffb83"
   },
   "outputs": [],
   "source": [
    "# check if there is any missing value and their data types\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fV6H8n11WYAx"
   },
   "outputs": [],
   "source": [
    "# remove \"NT$\" then convert store_sales and store_cost to float\n",
    "df[\"store_sales\"] = [float(sale[3:]) if type(sale) == str else sale for sale in df[\"store_sales\"]]\n",
    "df[\"store_cost\"] = [float(sale[3:]) if type(sale) == str else sale for sale in df[\"store_cost\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665765694725,
     "user": {
      "displayName": "何子安",
      "userId": "06861626017998849506"
     },
     "user_tz": -480
    },
    "id": "YelMpqZqSErX",
    "outputId": "593e1573-3114-4be7-c3fe-23a168a6aef9"
   },
   "outputs": [],
   "source": [
    "df[\"store_sales\"].dtype, df[\"store_cost\"].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jryUbX9foLyj",
    "outputId": "aa41a334-c4fa-43cd-ba3d-920502182c01"
   },
   "outputs": [],
   "source": [
    "# drop store_sales, store_cost, unit_sales columns\n",
    "to_use = [\"customer_id\", \"time_id\", \"store_id\", \"promotion_id\", \"product_id\"]\n",
    "df_done = df[to_use]\n",
    "#df_done.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## map out `product_id` from `product.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product = pd.read_csv(wdir + \"hw1_data/product.csv\")\n",
    "df_product.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product[\"product_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_done[\"product_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_product[[\"product_id\", \"product_name\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_name = {\n",
    "    p_id: p_name\n",
    "    for p_id, p_name in zip(df_product[\"product_id\"], df_product[\"product_name\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_done[\"product_name\"] = [id_name[p_id] for p_id in df_done[\"product_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qWqLL5-noLyk"
   },
   "source": [
    "## Input preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5Z7XsBKoLyl"
   },
   "source": [
    "### way 2 Groupby [\"customer_id\", \"time_id\", \"store_id\", \"promotion_id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can tell product class from `product_*.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGyVFgi8oLyl"
   },
   "outputs": [],
   "source": [
    "_df_groupby = df_done.sort_values(to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eg10_rxxoLyl",
    "outputId": "24198191-9b0e-4e2b-bbdc-7cce4776f4a4"
   },
   "outputs": [],
   "source": [
    "groupby_dict = {}\n",
    "for c, t, s, p, p_id, product_name in _df_groupby[:].values:\n",
    "    #print(c, t, s, p, product)\n",
    "    if (c, t, s, p) not in groupby_dict:\n",
    "        groupby_dict[(c, t, s, p)] = ()\n",
    "        _temp = groupby_dict[(c, t, s, p)] + (product_name, )\n",
    "        groupby_dict[(c, t, s, p)] = _temp\n",
    "    elif (c, t, s, p) in groupby_dict:\n",
    "        _temp = groupby_dict[(c, t, s, p)] + (product_name, )\n",
    "        groupby_dict[(c, t, s, p)] = _temp\n",
    "        \n",
    "groupby_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAvofnsFoLym"
   },
   "outputs": [],
   "source": [
    "transactions = [items for items in groupby_dict.values()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OZ4SbYyataBF"
   },
   "source": [
    "# Question 1\n",
    "請利用 **Apriori** 演算法，從 Foodmart 資料庫的交易資料中，探勘符合 `Minimum Support = 0.0001` 且 `Minimum Confidence = 0.9` 的 **Association Rules**，並列出 Confidence 最高的前 10 條 Rules 以及 lift 最高的前 10 條，並比較這兩者的異同。若無法跑出結果，請簡述其原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyd9jCZJoLyn"
   },
   "source": [
    "using fastest apriori algorithm from https://efficient-apriori.readthedocs.io/en/latest/?badge=latest\n",
    "\n",
    "others apriori algorithms:\n",
    "- https://github.com/ymoch/apyori\n",
    "    - https://stackabuse.com/association-rule-mining-via-apriori-algorithm-in-python/\n",
    "    - https://ubiops.com/how-to-build-and-implement-a-recommendation-system-from-scratch-in-python/\n",
    "- https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/apriori/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76Tx-erIoLyn"
   },
   "outputs": [],
   "source": [
    "from efficient_apriori import apriori"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oYaUKwjdoLyn",
    "outputId": "5a1eb4ca-99cd-4283-cde9-3cfc7c13c116"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "itemsets, rules = apriori(transactions, min_support=0.0001, min_confidence=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vnoiBo8toLyo",
    "outputId": "91191278-2fc7-42b9-835c-8be3468ebeb7"
   },
   "outputs": [],
   "source": [
    "print(f\"having {len(itemsets)} itemsets.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5Vcri9O1oLyo",
    "outputId": "b5ad90ba-1ccd-4ece-e374-2dbc61b46cec"
   },
   "outputs": [],
   "source": [
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ws9gQtG2oLyp"
   },
   "source": [
    "## 10 highest confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5shYc44DoLyp"
   },
   "outputs": [],
   "source": [
    "confidences = [rule.confidence for rule in rules]\n",
    "print(min(confidences), max(confidences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rule in rules:\n",
    "    print(rule.confidence, rule)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Kwen08OoLyp"
   },
   "source": [
    "## 10 highest lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlLj8VCzoLyp"
   },
   "outputs": [],
   "source": [
    "lifts = [rule.lift for rule in rules]\n",
    "print(min(lifts), max(lifts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rule in rules:\n",
    "    if rule.lift > 9000:\n",
    "        print(rule.lift, rule)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da9ioZ9EoLyp"
   },
   "source": [
    "## difference between 10 highest confidence and 10 highest lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "82X6dGnaoLyp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_hnuym0ox-E"
   },
   "source": [
    "# Question 2\n",
    "請利用 **FP-Growth** 演算法，從 Foodmart 資料庫的交易資料中，探勘符合 `Minimum Support = 0.0001` 且 `Minimum Confidence = 0.9` 的 **Association Rules**，並列出 Confidence 最高的前 10 條 Rules 以及 lift 最高的前 10 條，並比較這兩者的異同。若無法跑出結果，請簡述其原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FP-Growth algorithm from: https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/fpgrowth/\n",
    "- https://rasbt.github.io/mlxtend/user_guide/frequent_patterns/association_rules/#metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [list(data) for data in groupby_dict.values()]\n",
    "#dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TransactionEncoder()\n",
    "te_array = te.fit_transform(dataset)\n",
    "df_te = pd.DataFrame(te_array, columns=te.columns_)\n",
    "#df_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fq_itemsets = fpgrowth(df_te, min_support=0.0001, use_colnames=True)\n",
    "#fq_itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules = association_rules(fq_itemsets, metric=\"confidence\", min_threshold=0.9)\n",
    "rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 highest confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules.sort_values([\"confidence\"])[::-1][:10][[\"antecedents\", \"consequents\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 highest lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rules.sort_values([\"lift\"])[::-1][:10][[\"antecedents\", \"consequents\"]].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## difference between 10 highest confidence and 10 highest lift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "有時候我們有興趣的資料不只有產品間的資訊,也會想要由 User Profile 探勘顧客的基本資料。\n",
    "\n",
    "在給定 `Minimum Support = 0.05` 且 `Minimum Confidence = 0.9` 的條件下, 探勘 Foodmart 顧客基本資料的屬性 `{State_Province, Yearly_Income, Gender, Total_Children, Num_Children_at_Home, Education, Occupation, Houseowner, Num_cars,owned}` 間的 **association rule**。(列出 10 條)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "library: https://github.com/firefly-cpp/NiaARM\n",
    "- https://niaarm.readthedocs.io/en/latest/getting_started.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from niaarm import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers = pd.read_csv(f\"{wdir}/hw1_data/customer.csv\")\n",
    "df_customers.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers = df_customers[[\n",
    "    \"state_province\", \"yearly_income\", \"gender\", \n",
    "    \"total_children\", \"num_children_at_home\", \"education\", \n",
    "    \"occupation\", \"houseowner\", \"num_cars_owned\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customers.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(df_customers)\n",
    "#print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from niapy.algorithms.basic import DifferentialEvolution\n",
    "from niaarm import get_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = DifferentialEvolution(\n",
    "    population_size=30, \n",
    "    differential_weight=0.8, \n",
    "    crossover_probability=0.9)\n",
    "\n",
    "#metrics = ('support', 'confidence', 'inclusion', 'amplitude')\n",
    "rules, run_time = get_rules(\n",
    "    dataset, algorithm, {\"support\": 0.0001, \"confidence\": 0.9}, max_iters=50, logging=False)\n",
    "rules.to_csv(wdir + 'niaarm_rules.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read `niaarm_rules.csv`\n",
    "df_niaarm_rules = pd.read_csv(wdir + \"niaarm_rules.csv\")\n",
    "df_niaarm_rules = df_niaarm_rules[[\"antecedent\", \"consequent\", \"fitness\", \"support\", \"confidence\", \"lift\"]]\n",
    "df_niaarm_rules_sorted = df_niaarm_rules.sort_values([\"lift\", \"support\", \"confidence\"])[::-1]\n",
    "for i, rule in enumerate(df_niaarm_rules_sorted[[\"antecedent\", \"consequent\"]][:10].values):\n",
    "    print(f\"rule{i+1}:\")\n",
    "    print(rule)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "請探勘 Foodmart 資料庫中,顧客背景資料與其交易資料之間的關係 (Quantitative Association Rules)。例如 80% 女性顧客常買保養品。請自行嘗試設定 `Minimum Support` `Minimum Confidence`, 找出 10 條你覺得有意義的 Rules。請說明你的作法及相關參數設定。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_fact_1998 = pd.read_csv(wdir + \"hw1_data/sales_fact_1998.csv\")\n",
    "sales_dec_1998 = pd.read_csv(wdir + \"hw1_data/sales_fact_dec_1998.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer = pd.read_csv(wdir + \"hw1_data/customer.csv\")\n",
    "df_sales = pd.concat([sales_fact_1998, sales_dec_1998], ignore_index=True)\n",
    "print(df_sales.shape, df_customer.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(df_customer.columns)\n",
    "df_customer.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if gonna map sales product_id\n",
    "df_product = pd.read_csv(wdir + \"hw1_data/product.csv\")\n",
    "\n",
    "id_name = {\n",
    "    p_id: p_name\n",
    "    for p_id, p_name in zip(df_product[\"product_id\"], df_product[\"product_name\"])}\n",
    "\n",
    "df_sales[\"product_name\"] = [id_name[p_id] for p_id in df_sales[\"product_id\"]]\n",
    "df_sales.sample(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some ideas:\n",
    "- groupby `customer_id` -> product_name\n",
    "    - map ('birthdate', 'marital_status', 'yearly_income', 'gender', 'total_children', 'num_children_at_home', 'education', 'occupation', 'houseowner', 'num_cars_owned')\n",
    "- groupby `time_id` -> product_name\n",
    "    - map ('the_month')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_customer = df_customer[[\n",
    "    \"customer_id\", \"state_province\", \"yearly_income\", \"gender\", \n",
    "    \"total_children\", \"num_children_at_home\", \"education\", \n",
    "    \"occupation\", \"houseowner\", \"num_cars_owned\"]]\n",
    "df_customer.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = pd.merge(df_sales, df_customer, on=[\"customer_id\"])\n",
    "print(df_join.shape)\n",
    "df_join.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join = df_join[[\n",
    "    \"product_name\", \"yearly_income\", \n",
    "    \"gender\", \"total_children\", \"education\", \n",
    "    \"occupation\", \"houseowner\", \"num_cars_owned\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_join[\"promotion_id\"] = [1 if p != 0 else 0 for p in df_join[\"promotion_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from niaarm import Dataset\n",
    "from niapy.algorithms.basic import DifferentialEvolution\n",
    "from niaarm import get_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(df_join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm = DifferentialEvolution(\n",
    "    population_size=30, \n",
    "    differential_weight=0.8, \n",
    "    crossover_probability=0.9)\n",
    "\n",
    "rules, run_time = get_rules(\n",
    "    dataset, algorithm, {\"support\": 0.8, \"confidence\": 0.9}, max_iters=50, logging=True)\n",
    "print(len(rules))\n",
    "rules.to_csv(wdir + 'niaarm_rules_q4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read `niaarm_rules.csv`\n",
    "df_niaarm_rules = pd.read_csv(wdir + \"niaarm_rules_q4.csv\")\n",
    "df_niaarm_rules = df_niaarm_rules[[\"antecedent\", \"consequent\", \"fitness\", \"support\", \"confidence\", \"lift\"]]\n",
    "df_niaarm_rules_sorted = df_niaarm_rules.sort_values([\"confidence\"])[::-1]\n",
    "for i, rule in enumerate(df_niaarm_rules_sorted[[\"antecedent\", \"consequent\", \"confidence\"]][:20].values):\n",
    "    #print(f\"rule{i+1}:\")\n",
    "    print(rule)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "在美國由於聖誕節，12 月是購物的旺季。請探勘分析比較 12 月與 1 ~ 11 月的顧客購物行為。\n",
    "有哪些相似的地方，有哪些差異的地方？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "some ideas:\n",
    "- groupby `time_id` -> # of people buying\n",
    "    - map ('the_month')\n",
    "- groupby `time_id`, `product_id` -> # of total unit_sales\n",
    "    - map ('the_month'), ('product_class_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time = pd.read_csv(wdir + \"hw1_data/time_by_day.csv\")\n",
    "#df_time.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_12 = df_time[[\"time_id\", \"month_of_year\"]].loc[df_time[\"month_of_year\"] == 12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_time_1_11 = df_time[[\"time_id\", \"month_of_year\"]].loc[df_time[\"month_of_year\"] != 12]\n",
    "df_time_1_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = []\n",
    "not_d_id = [i for i in df_time_1_11[\"time_id\"].values]\n",
    "for t_id in df_sales[\"time_id\"]:\n",
    "    if t_id in not_d_id:\n",
    "        month.append(\"not_december\")\n",
    "    else:\n",
    "        month.append(\"december\")\n",
    "#month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'december' in month, \"not_december\" in month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales[\"month\"] = month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sales.loc[df_sales[\"month\"] == \"december\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_sales.loc[df_sales[\"month\"] == \"not_december\"]))\n",
    "len(df_sales.loc[df_sales[\"month\"] != \"december\"]) / 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sales.loc[df_sales[\"month\"] == \"december\"].loc[df_sales[\"promotion_id\"] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sales.loc[df_sales[\"month\"] == \"december\"].loc[df_sales[\"promotion_id\"] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sales.loc[df_sales[\"month\"] == \"not_december\"].loc[df_sales[\"promotion_id\"] == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sales.loc[df_sales[\"month\"] == \"not_december\"].loc[df_sales[\"promotion_id\"] != 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3278 / (3278 + 15047)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "44292 / (44292 + 120266)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b8fffb070d157b29bcbe373ef74d57cf4a2545d80c026126f07f9afc1e8a0fbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
